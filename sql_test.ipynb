{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing your data from the database\n",
    "\n",
    "- Please follow the steps in this notebook to have access to the dataset. \n",
    "- If you encounter any challenges please leave an issue on this repo here on GitHub"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to take to use environment variables as opposed to credentials literals\n",
    "\n",
    "1. Install pyodbc  - a package for creating connection strings to your remote database server\n",
    "2. Install python-dotenv - a package for creating environment variables that will help you hide sensitve configuration informantion such as database credentials and API keys\n",
    "3. Import all the necessary libraies\n",
    "   1. pyodbc (for creating a connection)\n",
    "   2. python-dotenv (loading environment variables)\n",
    "   3. os (for accessing the environement variables using the load_env function. This is not needed if you use the dotenv_values function instead)\n",
    "4. Now create a file called .env in the root of your project folder (Note, the file name begins with a dot)\n",
    "5. In the .env file, put all your sensitive information like server name, database name, username, and password\n",
    "\n",
    "Example\n",
    "\n",
    "   - SERVER='server_name_here'\n",
    "   - DATABASE='database_name_here'\n",
    "   - USERNAME='username_here'\n",
    "   - PASSWORD='password_here'\n",
    "\n",
    "\n",
    "6. Next create a .gitignore file (a new file with the name '.gitignore'. Note that gitignore file names begin with a dot)\n",
    "7. Open the .gitignore file and type in the name of the .env file we just created like this \"/.env\". This will prevent git from tracking that file. Essesntially any file name in the gitignore file will be ignored by git and won't be checked into the repository\n",
    "8. Create a connection by accessing your connection string with your defined environment variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 and 2 - Install pyodbc and python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pyodbc  \n",
    "# %pip install python-dotenv "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 - Import all the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc      #just installed with pip\n",
    "from dotenv import dotenv_values    #import the dotenv_values function from the dotenv package\n",
    "import pandas as pd\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 - Create your .env file in the root of your project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5 - In the .env file, put all your sensitive information like server name, password etc\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6 & 7 - Next create a .gitignore file and type '/.env' file we just created. This will prevent git from tracking that file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8 - Create a connection by accessing your connection string with your defined environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file into a dictionary\n",
    "environment_variables = dotenv_values('.env')\n",
    "\n",
    "\n",
    "# Get the values for the credentials you set in the '.env' file\n",
    "server = environment_variables.get(\"SERVER\")\n",
    "database = environment_variables.get(\"DATABASE\")\n",
    "username = environment_variables.get(\"USERNAME\")\n",
    "password = environment_variables.get(\"PASSWORD\")\n",
    "\n",
    "\n",
    "connection_string = f\"DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password};MARS_Connection=yes;MinProtocolVersion=TLSv1.2;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the connect method of the pyodbc library and pass in the connection string.\n",
    "# This will connect to the server and might take a few seconds to be complete. \n",
    "# Check your internet connection if it takes more time than necessary\n",
    "\n",
    "connection = pyodbc.connect(connection_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the sql query to get the data is what what you see below. \n",
    "# Note that you will not have permissions to insert delete or update this database table. \n",
    "\n",
    "query = \"Select * from LP1_startup_funding2020\"\n",
    "\n",
    "data = pd.read_sql(query, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Brand</th>\n",
       "      <th>Founded</th>\n",
       "      <th>HeadQuarter</th>\n",
       "      <th>Sector</th>\n",
       "      <th>What_it_does</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Stage</th>\n",
       "      <th>column10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aqgromalin</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>AgriTech</td>\n",
       "      <td>Cultivating Ideas for Profit</td>\n",
       "      <td>Prasanna Manogaran, Bharani C L</td>\n",
       "      <td>Angel investors</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Krayonnz</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>An academy-guardian-scholar centric ecosystem ...</td>\n",
       "      <td>Saurabh Dixit, Gurudutt Upadhyay</td>\n",
       "      <td>GSF Accelerator</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Pre-seed</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PadCare Labs</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Hygiene management</td>\n",
       "      <td>Converting bio-hazardous waste to harmless waste</td>\n",
       "      <td>Ajinkya Dhariya</td>\n",
       "      <td>Venture Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pre-seed</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCOME</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Escrow</td>\n",
       "      <td>Escrow-as-a-service platform</td>\n",
       "      <td>Ritesh Tiwari</td>\n",
       "      <td>Venture Catalysts, PointOne Capital</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gramophone</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Indore</td>\n",
       "      <td>AgriTech</td>\n",
       "      <td>Gramophone is an AgTech platform enabling acce...</td>\n",
       "      <td>Ashish Rajan Singh, Harshit Gupta, Nishant Mah...</td>\n",
       "      <td>Siana Capital Management, Info Edge</td>\n",
       "      <td>340000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>Leverage Edu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Edtech</td>\n",
       "      <td>AI enabled marketplace that provides career gu...</td>\n",
       "      <td>Akshay Chaturvedi</td>\n",
       "      <td>DSG Consumer Partners, Blume Ventures</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>EpiFi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Fintech</td>\n",
       "      <td>It offers customers with a single interface fo...</td>\n",
       "      <td>Sujith Narayanan, Sumit Gwalani</td>\n",
       "      <td>Sequoia India, Ribbit Capital</td>\n",
       "      <td>13200000.0</td>\n",
       "      <td>Seed Round</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>Purplle</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Cosmetics</td>\n",
       "      <td>Online makeup and beauty products retailer</td>\n",
       "      <td>Manish Taneja, Rahul Dash</td>\n",
       "      <td>Verlinvest</td>\n",
       "      <td>8000000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>Shuttl</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Transport</td>\n",
       "      <td>App based bus aggregator serice</td>\n",
       "      <td>Amit Singh, Deepanshu Malviya</td>\n",
       "      <td>SIG Global India Fund LLP.</td>\n",
       "      <td>8043000.0</td>\n",
       "      <td>Series C</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>Pando</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Logitech</td>\n",
       "      <td>Networked logistics management software</td>\n",
       "      <td>Jayakrishnan, Abhijeet Manohar</td>\n",
       "      <td>Chiratae Ventures</td>\n",
       "      <td>9000000.0</td>\n",
       "      <td>Series A</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1055 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Company_Brand  Founded HeadQuarter              Sector  \\\n",
       "0       Aqgromalin   2019.0     Chennai            AgriTech   \n",
       "1         Krayonnz   2019.0   Bangalore              EdTech   \n",
       "2     PadCare Labs   2018.0        Pune  Hygiene management   \n",
       "3            NCOME   2020.0   New Delhi              Escrow   \n",
       "4       Gramophone   2016.0      Indore            AgriTech   \n",
       "...            ...      ...         ...                 ...   \n",
       "1050  Leverage Edu      NaN       Delhi              Edtech   \n",
       "1051         EpiFi      NaN        None             Fintech   \n",
       "1052       Purplle   2012.0      Mumbai           Cosmetics   \n",
       "1053        Shuttl   2015.0       Delhi           Transport   \n",
       "1054         Pando   2017.0     Chennai            Logitech   \n",
       "\n",
       "                                           What_it_does  \\\n",
       "0                          Cultivating Ideas for Profit   \n",
       "1     An academy-guardian-scholar centric ecosystem ...   \n",
       "2      Converting bio-hazardous waste to harmless waste   \n",
       "3                          Escrow-as-a-service platform   \n",
       "4     Gramophone is an AgTech platform enabling acce...   \n",
       "...                                                 ...   \n",
       "1050  AI enabled marketplace that provides career gu...   \n",
       "1051  It offers customers with a single interface fo...   \n",
       "1052         Online makeup and beauty products retailer   \n",
       "1053                    App based bus aggregator serice   \n",
       "1054            Networked logistics management software   \n",
       "\n",
       "                                               Founders  \\\n",
       "0                       Prasanna Manogaran, Bharani C L   \n",
       "1                      Saurabh Dixit, Gurudutt Upadhyay   \n",
       "2                                       Ajinkya Dhariya   \n",
       "3                                         Ritesh Tiwari   \n",
       "4     Ashish Rajan Singh, Harshit Gupta, Nishant Mah...   \n",
       "...                                                 ...   \n",
       "1050                                  Akshay Chaturvedi   \n",
       "1051                    Sujith Narayanan, Sumit Gwalani   \n",
       "1052                          Manish Taneja, Rahul Dash   \n",
       "1053                      Amit Singh, Deepanshu Malviya   \n",
       "1054                     Jayakrishnan, Abhijeet Manohar   \n",
       "\n",
       "                                   Investor      Amount       Stage column10  \n",
       "0                           Angel investors    200000.0        None     None  \n",
       "1                           GSF Accelerator    100000.0    Pre-seed     None  \n",
       "2                            Venture Center         NaN    Pre-seed     None  \n",
       "3       Venture Catalysts, PointOne Capital    400000.0        None     None  \n",
       "4       Siana Capital Management, Info Edge    340000.0        None     None  \n",
       "...                                     ...         ...         ...      ...  \n",
       "1050  DSG Consumer Partners, Blume Ventures   1500000.0        None     None  \n",
       "1051          Sequoia India, Ribbit Capital  13200000.0  Seed Round     None  \n",
       "1052                             Verlinvest   8000000.0        None     None  \n",
       "1053             SIG Global India Fund LLP.   8043000.0    Series C     None  \n",
       "1054                      Chiratae Ventures   9000000.0    Series A     None  \n",
       "\n",
       "[1055 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('LP2_Telco-churn-last-2000.csv')\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can concatenate this with other DataFrames to get one data set for your work\n",
    "\n",
    "df = pd.concat([data, data2])\n",
    "\n",
    "df.to_csv('aba.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shapes of the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
